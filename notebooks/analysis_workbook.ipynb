{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "from matplotlib.pyplot import subplots\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "database_password = os.environ.get(\"DATABASE_PASSWORD\")\n",
    "database_username = os.environ.get(\"DATABASE_USERNAME\")\n",
    "database_host = os.environ.get(\"DATABASE_HOST\")\n",
    "database_port = os.environ.get(\"DATABASE_PORT\")\n",
    "database_name = os.environ.get(\"DATABASE_NAME\")\n",
    "\n",
    "connection = psycopg2.connect(database=database_name,\n",
    "                        host=database_host,\n",
    "                        user=database_username,\n",
    "                        password=database_password,\n",
    "                        port=database_port)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sql_to_dataframe(conn, query) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Import data from a PostgreSQL database using a SELECT query\n",
    "    \"\"\"\n",
    "    cursor = conn.cursor()\n",
    "    try:\n",
    "        cursor.execute(query)\n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "        print(f\"Error: {error}â€\")\n",
    "        cursor.close()\n",
    "        return 1\n",
    "    # The execute returns a list of tuples:\n",
    "    tuples_list = cursor.fetchall()\n",
    "    colnames = [desc[0] for desc in cursor.description]\n",
    "    cursor.close()\n",
    "    # Now we need to transform the list into a pandas DataFrame:\n",
    "    df = pd.DataFrame(tuples_list, columns=colnames)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jobs live on Wednesdays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs_live_df = sql_to_dataframe(conn=connection, query=\"\"\"SELECT DATE(checked_time), COUNT(DISTINCT scrapeid)\n",
    "\tFROM (SELECT * FROM sitemap_entries\n",
    "\t\tWHERE checked_time > '2024-01-10' AND NOT checked_time = '2024-02-10 01:36:09.964627+00'\n",
    "\t\tORDER BY checked_time ASC) m\n",
    "GROUP BY DATE(checked_time)\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs_live_df['date'] = pd.to_datetime(jobs_live_df['date'])\n",
    "\n",
    "# Filter the DataFrame to only include Wednesdays (where dayofweek == 2)\n",
    "wednesdays_df = jobs_live_df[jobs_live_df['date'].dt.dayofweek == 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = subplots(figsize=(10,6))\n",
    "\n",
    "ax.plot(wednesdays_df[\"date\"], wednesdays_df[\"count\"], marker=\"+\", markeredgecolor=\"red\")\n",
    "\n",
    "ax.set_ylim(bottom=0)\n",
    "\n",
    "ax.set_title(\"Number of jobs live on Civil Service Jobs\")\n",
    "\n",
    "ax.set_ylabel(\"Number of jobs live\")\n",
    "\n",
    "ax.set_xticks(wednesdays_df[\"date\"])\n",
    "ax.tick_params(axis='x', rotation=70)\n",
    "\n",
    "fig.subplots_adjust(bottom=0.25)\n",
    "\n",
    "fig.text(0.5, 0.01, \"(Quick, non peer-reviewed visualisation based on unofficial once-daily web scraping. \\n Civil Service Jobs data is available under the Open Government Licence v3.0)\", ha=\"center\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Total new jobs added per day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "earliest_times_per_jcode_df = sql_to_dataframe(conn=connection, query=\"SELECT jcode, COUNT(DISTINCT scrapeid), MIN(checked_time) AS earliest_checked_time, MIN(updated_time) AS earliest_updated_time FROM sitemap_entries GROUP BY jcode\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "earliest_times_per_jcode_df[\"earliest_updated_time\"] = pd.to_datetime(earliest_times_per_jcode_df[\"earliest_updated_time\"], utc=True)\n",
    "\n",
    "df_counts_by_date = earliest_times_per_jcode_df.groupby(earliest_times_per_jcode_df[\"earliest_updated_time\"].dt.date).size().reset_index(name=\"count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_counts_by_date[\"earliest_updated_time\"] = pd.to_datetime(df_counts_by_date[\"earliest_updated_time\"])\n",
    "df_counts_by_date = df_counts_by_date[df_counts_by_date[\"earliest_updated_time\"] >= pd.to_datetime(\"2024-01-11\")]\n",
    "df_counts_by_date.set_index(\"earliest_updated_time\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_counts_by_date = df_counts_by_date.asfreq('D', fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = subplots(figsize=(10,6))\n",
    "\n",
    "ax.plot(df_counts_by_date.index, df_counts_by_date[\"count\"])\n",
    "\n",
    "ax.set_ylim(bottom=0)\n",
    "\n",
    "ax.set_title(\"Number of new jobs posted on Civil Service Jobs per day\")\n",
    "\n",
    "ax.set_ylabel(\"Number of new jobs posted\")\n",
    "\n",
    "fig.subplots_adjust(bottom=0.15)\n",
    "\n",
    "fig.text(0.5, 0.01, \"(Quick, non peer-reviewed visualisation based on unofficial once-daily web scraping. \\n Civil Service Jobs data is available under the Open Government Licence v3.0)\", ha=\"center\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Total new jobs added per week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "earliest_times_per_jcode_df_for_week = sql_to_dataframe(conn=connection, query=\"SELECT jcode, COUNT(DISTINCT scrapeid), MIN(checked_time) AS earliest_checked_time, MIN(updated_time) AS earliest_updated_time FROM sitemap_entries GROUP BY jcode\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "earliest_times_per_jcode_df_for_week[\"earliest_updated_time\"] = pd.to_datetime(earliest_times_per_jcode_df_for_week[\"earliest_updated_time\"], utc=True)\n",
    "df_counts_by_week = earliest_times_per_jcode_df_for_week.groupby(earliest_times_per_jcode_df_for_week[\"earliest_updated_time\"].dt.to_period('W')).size().to_timestamp().reset_index(name=\"count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_counts_by_week[\"earliest_updated_time\"] = pd.to_datetime(df_counts_by_week[\"earliest_updated_time\"])\n",
    "df_counts_by_week = df_counts_by_week[df_counts_by_week[\"earliest_updated_time\"] >= pd.to_datetime(\"2024-01-15\")]\n",
    "df_counts_by_week = df_counts_by_week[df_counts_by_week[\"earliest_updated_time\"] <= pd.to_datetime(\"2024-03-24\")]\n",
    "df_counts_by_week.set_index(\"earliest_updated_time\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_counts_by_week = df_counts_by_week.asfreq('W-MON', fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = subplots(figsize=(14,6))\n",
    "\n",
    "ax.plot(df_counts_by_week.index, df_counts_by_week[\"count\"], marker=\"+\", markeredgecolor=\"red\")\n",
    "\n",
    "ax.set_ylim(bottom=0)\n",
    "\n",
    "ax.set_title(\"Number of new jobs posted on Civil Service Jobs per week\")\n",
    "\n",
    "ax.set_ylabel(\"Number of new jobs posted\")\n",
    "\n",
    "ax.set_xticks(df_counts_by_week.index)\n",
    "\n",
    "fig.subplots_adjust(bottom=0.15)\n",
    "\n",
    "fig.text(0.5, 0.01, \"(Quick, non peer-reviewed visualisation based on unofficial once-daily web scraping. \\n Civil Service Jobs data is available under the Open Government Licence v3.0)\", ha=\"center\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jobs live on Wednesdays, for a specific department"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "earliest_times_per_jcode_df_for_week = sql_to_dataframe(conn=connection, query=\"SELECT jcode, COUNT(DISTINCT scrapeid), MIN(checked_time) AS earliest_checked_time, MIN(updated_time) AS earliest_updated_time FROM sitemap_entries GROUP BY jcode\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
